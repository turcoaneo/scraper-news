{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-01T07:22:44.423525100Z",
     "start_time": "2025-10-01T07:16:18.486121Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "def extract_entities_keywords(p_summary):\n",
    "    prompt = f\"\"\"\n",
    "    Extract named entities and keywords from the following Romanian sports news summary.\n",
    "    Only extract named entities such as people, organizations, teams, competitions, and locations. Do NOT include dates, weekdays, or generic terms.\n",
    "    Extract relevant keywords that describe the themes, actions, or context of the summary. Avoid repeating named entities or generic filler words.\n",
    "\n",
    "    Summary: \"{p_summary}\"\n",
    "\n",
    "    Return a valid JSON object with two fields: \"entities\" and \"keywords\".\n",
    "    Each field should be a list of strings.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # ✅ Use .choices[0].message.content (not response['choices'][0]...)\n",
    "    result_text = response.choices[0].message.content\n",
    "\n",
    "    # ✅ Safer than eval — use json.loads\n",
    "    import json\n",
    "    try:\n",
    "        return json.loads(result_text)\n",
    "    except json.JSONDecodeError as err:\n",
    "        print(f\"JSON decode error: {err}\")\n",
    "        print(f\"Raw response: {result_text}\")\n",
    "        return {\"entities\": [], \"keywords\": []}\n",
    "\n",
    "\n",
    "input_file = \"storage/test_gpt_input_corrupt.csv\"\n",
    "output_file = \"storage/test_gpt_output_corrupt.csv\"\n",
    "\n",
    "with open(input_file, encoding=\"utf-8\") as infile, open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    next(reader)\n",
    "    writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)\n",
    "    writer.writerow([\"summary\", \"entities\", \"keywords\"])  # Header\n",
    "\n",
    "    for row in reader:\n",
    "        if len(row) < 3:\n",
    "            continue  # Skip malformed rows\n",
    "        summary = row[2].strip()\n",
    "        try:\n",
    "            result = extract_entities_keywords(summary)\n",
    "            entities = \",\".join(result[\"entities\"])\n",
    "            keywords = \",\".join(result[\"keywords\"])\n",
    "            writer.writerow([summary, entities, keywords])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {summary[:50]}... → {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3ab5b0dbe21ea13c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
