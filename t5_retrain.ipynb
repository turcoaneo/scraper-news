{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-11T10:51:27.244615200Z",
     "start_time": "2025-10-11T10:51:26.339459100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Your Existing Model\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_path = \"t5_decorator_model\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Add New Duplet\n",
    "from storage.duplets_dictionary import duplets, new_duplets\n",
    "duplets += new_duplets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-11T10:35:29.629123500Z",
     "start_time": "2025-10-11T10:35:29.613886Z"
    }
   },
   "id": "7d96400663fd9a29"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Train/Validation Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_duplets, val_duplets = train_test_split(duplets, test_size=0.1, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-11T10:35:31.195279100Z",
     "start_time": "2025-10-11T10:35:31.135125300Z"
    }
   },
   "id": "8c61d4d59058e9a9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DupletDataset(Dataset):\n",
    "    def __init__(self, p_duplets, p_tokenizer, max_length=32):\n",
    "        self.duplets = p_duplets\n",
    "        self.tokenizer = p_tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.duplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p_input_text = f\"normalize: {self.duplets[idx][0]}\"\n",
    "        target_text = self.duplets[idx][1]\n",
    "        input_ids = self.tokenizer(p_input_text, truncation=True, padding=\"max_length\", max_length=self.max_length).input_ids\n",
    "        labels = self.tokenizer(target_text, truncation=True, padding=\"max_length\", max_length=self.max_length).input_ids\n",
    "        return {\"input_ids\": input_ids, \"labels\": labels}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-11T10:35:32.427386400Z",
     "start_time": "2025-10-11T10:35:32.417490300Z"
    }
   },
   "id": "e911d0f6e2d24e1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Trainer Setup\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "train_dataset = DupletDataset(train_duplets, tokenizer)\n",
    "val_dataset = DupletDataset(val_duplets, tokenizer)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./t5_decorator_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=25,\n",
    "    logging_dir=\"./logs\",\n",
    "    predict_with_generate=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    dataloader_pin_memory=False,  # üëà disables pin_memory\n",
    ")\n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Strip whitespace\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.strip() for label in decoded_labels]\n",
    "\n",
    "    # Compute exact match accuracy\n",
    "    acc = accuracy_score(decoded_labels, decoded_preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-11T10:35:38.951954Z",
     "start_time": "2025-10-11T10:35:35.785765200Z"
    }
   },
   "id": "918dddba482cc8bf"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/525 : < :, Epoch 0.05/25]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=525, training_loss=0.08811043727965583, metrics={'train_runtime': 766.9177, 'train_samples_per_second': 5.281, 'train_steps_per_second': 0.685, 'total_flos': 34258393497600.0, 'train_loss': 0.08811043727965583, 'epoch': 25.0})"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-11T10:48:30.108877Z",
     "start_time": "2025-10-11T10:35:42.936854200Z"
    }
   },
   "id": "b6ac5f754bdafab1"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ copilului ‚Üí copil\n",
      "‚úÖ copiii ‚Üí copii\n",
      "‚úÖ mamei ‚Üí mama\n",
      "‚úÖ mamelor ‚Üí mame\n",
      "‚úÖ fratelui ‚Üí frate\n",
      "‚úÖ sportivilor ‚Üí sportivi\n",
      "‚úÖ echipelor locale ‚Üí echipe locale\n",
      "‚ùå manelei ‚Üí mane»õi (expected: manea)\n",
      "‚úÖ acadelei ‚Üí acadea\n",
      "‚ùå Stelei Bucure»ôti ‚Üí Stel Bucure»ôti (expected: Steaua Bucure»ôti)\n",
      "‚úÖ Stelei ‚Üí Steaua\n",
      "‚úÖ Unirii ‚Üí Unirea\n",
      "‚úÖ Sibiului ‚Üí Sibiu\n",
      "‚úÖ jucƒÉtoarei ‚Üí jucƒÉtoare\n",
      "‚úÖ fotbalistelor tinere ‚Üí fotbaliste tinere\n",
      "‚úÖ rugbi»ôtilor francezi ‚Üí rugbi»ôti francezi\n",
      "‚úÖ cetƒÉ»õeanului ‚Üí cetƒÉ»õean\n",
      "‚úÖ comisiilor ‚Üí comisii\n",
      "‚úÖ prefec»õilor ‚Üí prefec»õi\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_path = \"t5_decorator_model\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "from storage.duplets_dictionary import test_cases, normalize\n",
    "\n",
    "for input_text, expected_output in test_cases:\n",
    "    predicted_output = normalize(input_text, tokenizer, model)\n",
    "    if predicted_output != expected_output:\n",
    "        print(f\"‚ùå {input_text} ‚Üí {predicted_output} (expected: {expected_output})\")\n",
    "    else:\n",
    "        print(f\"‚úÖ {input_text} ‚Üí {predicted_output}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-11T11:46:14.528110800Z",
     "start_time": "2025-10-11T11:46:11.074839600Z"
    }
   },
   "id": "288e47ebc6e299a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
